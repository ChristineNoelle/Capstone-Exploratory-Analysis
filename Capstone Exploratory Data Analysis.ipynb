{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9ec7d2",
   "metadata": {},
   "source": [
    "# Capstone Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First importing all libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import math \n",
    "import scipy.stats as stats\n",
    "import scipy.optimize\n",
    "from scipy.optimize import minimize\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from random import shuffle, seed\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import set_config\n",
    "from random import shuffle, seed\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import set_config\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, precision_recall_curve, roc_curve, f1_score, roc_auc_score\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import scipy\n",
    "import surprise\n",
    "from sklearn.cluster import DBSCAN\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, SVD, Dataset, NormalPredictor, KNNBasic, SlopeOne, CoClustering, NMF, SlopeOne\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d763f",
   "metadata": {},
   "source": [
    "# Understanding the Data\n",
    "This data set is from Kaggle.com, specifically a Spotify data set.  The data set title is \"Music Recommendation System Using Spotify Dataset.  There are 15 features - in addition to Artist, Song Title, and Unique ID - that I placed in the following categories: Time-Related (Year, Release Date, Tempo, Duration, Popularity), Music Features (Danceability, Acousticness, Energy, Instrumentalness, Key, Liveness, Loudness, Mode), Lyric-Related (Speechiness, Explicit). The outcome variable will be Valence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbdcfb",
   "metadata": {},
   "source": [
    "# Understanding the Research Question: Is It Possible to Predict Valence From Musical Features, Thereby Enhancing Music Recommendation Systems?\n",
    "\n",
    "Valence is a measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry). Can the target outcome, for negative or positive valence, be predicted via the features in music? This question is important because music recommendation systems are important to particular clinical populations in persons that consider music highly important.  For example, persons with dementia may benefit from positive memories that music evokes. If musical features can predict positive valence, for instance, these features can be used to recommend music that may benefit quality of life for an individual. \n",
    "\n",
    "Regarding this data set, I first examined, cleaned, and prepared the data for further analysis. Next, I performed L1 Regularization in Logistic Regression. The resulting top feature was Danceability. Finally, I compared simple models for Logistic Regression, KNN, and Decision Trees.  The optimal model was the Decision Tree model, and I also searched optimal parameters for the Decision Tree Model. Next steps are to categorize the outcome variable, Valence, into four classes rather than two classes. More models can then be compared via accuracy scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8614947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading main data set\n",
    "TestCap = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c668e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad2582",
   "metadata": {},
   "source": [
    "### Exploring Data Set Initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2602be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCap.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCap.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74976e89",
   "metadata": {},
   "source": [
    "##### No Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0608f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCap.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCap.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCap.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c78d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCapDF = pd.DataFrame(TestCap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1920ff",
   "metadata": {},
   "source": [
    "### Cleaning Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a783a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Columns\n",
    "NewDF = TestCapDF.rename({'valence': 'Valence', \n",
    "                   'year': 'Release_Year', \n",
    "                   'acousticness': 'Acousticness',\n",
    "                   'artists': 'Artist', \n",
    "                   'danceability': 'Danceability',\n",
    "                   'duration_ms': 'Duration(ms)',\n",
    "                   'energy': 'Energy', \n",
    "                   'explicit': 'Explicit', \n",
    "                   'id': 'ID', \n",
    "                   'instrumentalness': 'Instrumentalness', \n",
    "                   'key': 'Key',\n",
    "                   'liveness': 'Liveness', \n",
    "                   'loudness': 'Loudness', \n",
    "                   'mode': 'Mode', \n",
    "                   'name': 'Song_Title', \n",
    "                   'popularity': 'Popularity', \n",
    "                   'release_date': 'Release_Date',\n",
    "                   'speechiness': 'Speechiness', \n",
    "                   'tempo': 'Tempo'},\n",
    "                        axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0fa207",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9c501",
   "metadata": {},
   "source": [
    "### Checking for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201aa6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Duplicated = NewDF.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d21a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b61550",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDF = NewDF.drop_duplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb870a3a",
   "metadata": {},
   "source": [
    "#### No Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b502cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd50a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Valence'])\n",
    "plt.title('Valence Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee42f5",
   "metadata": {},
   "source": [
    "#### Valence - A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e94aa0",
   "metadata": {},
   "source": [
    "### Transforming Valence column for future analysis\n",
    "Binary Outcome, 4-Category Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe49989",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDF['Valence_2Cat'] = pd.cut(x=NewDF['Valence'],\n",
    "                               bins=[0,.5,1],\n",
    "                               labels = ['Negative', 'Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDF['Valence_2Cat'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05428a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDF['Valence_4Cat'] = pd.cut(x=NewDF['Valence'],\n",
    "                               bins = [0,.25,.50, .75, 1],\n",
    "                               labels = ['Lower_Negative', \n",
    "                                         'Upper_Negative', \n",
    "                                         'Lower_Positive', \n",
    "                                         'Upper_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654139e9",
   "metadata": {},
   "source": [
    "### Examining Columns and Obtaining Definitions for Clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48519174",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Release_Year'])\n",
    "plt.title('Release Year Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Acousticness'])\n",
    "plt.title('Acousticness Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12a1625",
   "metadata": {},
   "source": [
    "#### Acousticness - A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a668ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Danceability'])\n",
    "plt.title('Dancability Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a62c391",
   "metadata": {},
   "source": [
    "#### Danceability - Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e231216",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Duration(ms)'])\n",
    "plt.title('Duration (ms) Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming Duration to Minutes\n",
    "NewDF['Duration_Mins'] = (NewDF['Duration(ms)']/1000)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Energy'])\n",
    "plt.title('Energy Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455e160",
   "metadata": {},
   "source": [
    "#### Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Explicit'])\n",
    "plt.title('Explicit Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Instrumentalness'])\n",
    "plt.title('Instrumentalness Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b18e4e",
   "metadata": {},
   "source": [
    "#### Instrumentalness - Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Liveness'])\n",
    "plt.title('Liveness Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f5a00",
   "metadata": {},
   "source": [
    "#### Liveness - Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live. The distribution of values for this feature look like this: Liveness distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Key'])\n",
    "plt.title('Key Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afabf0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Loudness'])\n",
    "plt.title('Loudness Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf7a1a",
   "metadata": {},
   "source": [
    "#### Loudness - The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Mode'])\n",
    "plt.title('Mode Count') #Major or Minor Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c414280",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Popularity'])\n",
    "plt.title('Popularity Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Speechiness'])\n",
    "plt.title('Speechiness Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb86e7a",
   "metadata": {},
   "source": [
    "#### Speechiness - Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NewDF['Tempo'])\n",
    "plt.title('Tempo Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b676a0b",
   "metadata": {},
   "source": [
    "#### Tempo - The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7cc861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping variables not adding meaning\n",
    "NewDFDrop = NewDF.drop(['ID', 'Release_Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f669a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDFDrop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cdbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining Song Title and Artist columns\n",
    "NewDFDrop[\"Title_Artist\"] = NewDFDrop['Song_Title'].astype(str) +\"-\"+ NewDFDrop['Artist'].astype(str)\n",
    "print(NewDFDrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDFDrop2 = NewDFDrop.drop(['Song_Title', 'Artist', 'Duration(ms)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDFDrop2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f173a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Title and Arist as Index \n",
    "MainDF = NewDFDrop2.set_index('Title_Artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a944f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5807953",
   "metadata": {},
   "source": [
    "## Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581886fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2 = NewDFDrop2.corr()\n",
    "plt.subplots(figsize=(12,7))\n",
    "sns.heatmap(corr2, annot = True).set(title = 'Numerical Variables Correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052ec33",
   "metadata": {},
   "source": [
    "#### There are no numerical variables that correlate sufficiently highly to remove the dimension.  In addition, Valence (outcome variable) correlates most highly with Danceability, Energy, and Loudness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc4e786",
   "metadata": {},
   "source": [
    "# Examining Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox = px.box(MainDF, x = 'Valence')\n",
    "figbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox2 = px.box(MainDF, x = 'Release_Year')\n",
    "figbox2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox3 = px.box(MainDF, x = 'Acousticness')\n",
    "figbox3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox5 = px.box(NewDF, x = 'Danceability')\n",
    "figbox5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaad5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox6 = px.box(MainDF, x = 'Duration_Mins')\n",
    "figbox6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39901dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting Duration Outliers\n",
    "DurationQuery = MainDF.query(\"Duration_Mins > .516 and Duration_Mins < 7.16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox7 = px.box(MainDF, x = 'Energy')\n",
    "figbox7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox8 = px.box(NewDF, x = 'Instrumentalness')\n",
    "figbox8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox9 = px.box(NewDF, x = 'Key')\n",
    "figbox9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox10 = px.box(MainDF, x = 'Liveness')\n",
    "figbox10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d509bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox11 = px.box(DurationQuery, x = 'Loudness')\n",
    "figbox11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48028c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting Loudness Outliers\n",
    "LoudnessQuery = DurationQuery.query(\"Loudness > -25.396\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534bf18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox11 = px.box(NewDF, x = 'Popularity')\n",
    "figbox11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox11 = px.box(MainDF, x = 'Speechiness')\n",
    "figbox11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SpeechinessQuery = LoudnessQuery.query(\"Speechiness < .14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002233d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "figbox11 = px.box(MainDF, x = 'Tempo')\n",
    "figbox11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting Tempo Outliers\n",
    "TempoQuery = SpeechinessQuery.query(\"Tempo > 30 and Tempo < 200.306\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fcca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "TempoQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewMainDF = TempoQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326ff51",
   "metadata": {},
   "source": [
    "## Setting Up Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcf5ca",
   "metadata": {},
   "source": [
    "### Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d343b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace rowv values\n",
    "NewMainDF[\"Key_Letter\"] = NewMainDF[[\"Key\"]].replace({0: \"C\", \n",
    "                                     1: \"C#Db\", \n",
    "                                     2: \"D\", \n",
    "                                     3: \"D#Eb\",\n",
    "                                     4: \"E\",\n",
    "                                     5: \"E#Fb\",\n",
    "                                     6: \"G\", \n",
    "                                     7: \"G#Ab\", \n",
    "                                     8: \"A\",\n",
    "                                     9: \"A#Bb\",\n",
    "                                     10: \"B\",\n",
    "                                     11: \"B#\",\n",
    "                                     -1: \"None\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dbaaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewMainDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff89acf",
   "metadata": {},
   "source": [
    "### Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewMainDF[\"Mode_Word\"] = NewMainDF[[\"Mode\"]].replace({0: \"Minor\",\n",
    "                                                      1: \"Major\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewMainDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34215083",
   "metadata": {},
   "source": [
    "## Setting Up Data Frame for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb4403",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDF = pd.DataFrame(NewMainDF[['Valence_2Cat',\n",
    "                                  'Release_Year',\n",
    "                                  'Acousticness',\n",
    "                                  'Danceability',\n",
    "                                  'Liveness',\n",
    "                                  'Loudness',\n",
    "                                  'Speechiness',\n",
    "                                  'Tempo',\n",
    "                                  'Key_Letter',\n",
    "                                  'Mode_Word',\n",
    "                                  'Duration_Mins']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDF['Valence_Binary'] = NewMainDF['Valence_2Cat'].replace({'Negative': 0, 'Positive': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFinal = FinalDF.drop(['Valence_2Cat'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c92bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f65ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset2 = FFinal.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350389ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFinalDF = reset2.drop(['Title_Artist'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFinalDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "DummiesKey = pd.get_dummies(FFinalDF['Key_Letter'])\n",
    "DummiesMode = pd.get_dummies(FFinalDF['Mode_Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33127953",
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop = FFinalDF.drop(['Key_Letter', 'Mode_Word'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02173efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline = pd.concat([DummiesKey, DummiesMode, Drop], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a1191",
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewBaseline = Baseline.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ba875",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewBaseline.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fd479d",
   "metadata": {},
   "source": [
    "### Shuffling Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ShuffleM1 = list(range(0, len(NewBaseline)))\n",
    "seed(42)\n",
    "shuffle(ShuffleM1)\n",
    "ShuffleM1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d37d0",
   "metadata": {},
   "source": [
    "### Cross-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46749d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = NewBaseline.drop(['Valence_Binary'], axis=1)\n",
    "y = NewBaseline['Valence_Binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f115889",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7288a8",
   "metadata": {},
   "source": [
    "### Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ee21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Intercept\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f924428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Coefficients\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bddc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_beta0 = logreg.intercept_\n",
    "logreg_beta1 = logreg.coef_\n",
    "logreg_thresh = -logreg_beta0/logreg_beta1\n",
    "\n",
    "logreg_beta0, logreg_beta1, logreg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Accuracy\n",
    "score = logreg.score(X_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcc1052",
   "metadata": {},
   "source": [
    "#### Baseline Performance That Classifier Should Aim to Beat (54.81%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Accuracy\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9cd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace8303",
   "metadata": {},
   "source": [
    "# Building Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35efebf1",
   "metadata": {},
   "source": [
    "#### Evaluating priority features via L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature and outcome variables\n",
    "X = NewBaseline.drop(['Valence_Binary'], axis=1)\n",
    "y = NewBaseline['Valence_Binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5146848",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-5, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a442ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list = []\n",
    "for C in Cs:\n",
    "    lgr = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = C, random_state=42, max_iter = 1000).fit(X_scaled, y)\n",
    "    coef_list.append(list(lgr.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefdc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(coef_list, columns = X.columns)\n",
    "coef_df.index = Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47212cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e256ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64e5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "plt.semilogx(coef_df)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.grid()\n",
    "plt.legend(list(coef_df.columns));\n",
    "plt.title('Increasing Regularization on Baseline Model')\n",
    "plt.xlabel(\"Increasing 1/C\")\n",
    "plt.savefig('coefl1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3badc",
   "metadata": {},
   "source": [
    "#### After evaluation, top feature is Danceability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f509efb",
   "metadata": {},
   "source": [
    "# Creating Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1954d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = NewBaseline[['Danceability']]\n",
    "y = NewBaseline['Valence_Binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723badc",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=NewBaseline, x='Valence_Binary')\n",
    "plt.title('Count of Target Observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d9e997",
   "metadata": {},
   "source": [
    "#### Appears sufficiently balanced for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902720f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = NewBaseline, x='Danceability', y='Valence_Binary', hue='Danceability')\n",
    "plt.title('Model Scatterplot: Valence by Danceability')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c82f2",
   "metadata": {},
   "source": [
    "# Scoring the Model\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952fe7b0",
   "metadata": {},
   "source": [
    "#### Performing Logistic Regression on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3259d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Intercept\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca9bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Coefficients\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ca64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_beta0 = logreg.intercept_\n",
    "logreg_beta1 = logreg.coef_\n",
    "logreg_thresh = -logreg_beta0/logreg_beta1\n",
    "logreg_beta0, logreg_beta1, logreg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98297240",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c257e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Intercept': ['-3.40'],\n",
    "     'Coefficient': ['6.89'],\n",
    "     'Threshold': ['0.49']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dff52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PreSimpleModelTable = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cda639",
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleModelTable = PreSimpleModelTable.set_index('Intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleModelTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining training accuracy for model\n",
    "score = logreg.score(X_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ac227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining test accuracy\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41b1ae",
   "metadata": {},
   "source": [
    "### Accuracy below baseline accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae3c8ad",
   "metadata": {},
   "source": [
    "# Setting Up  Model for Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8249c",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.head())\n",
    "print('==============')\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split with 30% of the data assigned as the test set\n",
    "#Set random_state = 42 to assure correct grading\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ea171",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNBasic = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 5))])\n",
    "KNNBasic.fit(X_train, y_train)\n",
    "KNNVBasic_acc_train = KNNBasic.score(X_train, y_train)\n",
    "KNNBasic_acc_test = KNNBasic.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23366116",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNVBasic_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a6f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNBasic_acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ed44d",
   "metadata": {},
   "source": [
    "#### Time to train was .1 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f922a6",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9724bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split with 30% of the data assigned as the test set\n",
    "#Set random_state = 42 to assure correct grading\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth = None, random_state = 42).fit(X_train, y_train)\n",
    "print(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a991dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_1 = dtree.get_depth()\n",
    "print(depth_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364bd887",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = dtree.score(X_train, y_train)\n",
    "test_acc = dtree.score(X_test, y_test)\n",
    "print(f'Training Accuracy: {train_acc: .3f}')\n",
    "print(f'Test Accuracy: {test_acc: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45a0fc",
   "metadata": {},
   "source": [
    "#### Time to train was .1 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efadd9af",
   "metadata": {},
   "source": [
    "# Improving Best Performing Model: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9edcfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8786fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing parameters for the decision tree model with various cross validation methods\n",
    "params = {'max_depth': [2,5,10],\n",
    "         'min_samples_split': [.1,.2,.05],\n",
    "          'criterion': ['gini', 'gini', 'gini'],\n",
    "          'min_samples_leaf': [1,10,20]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4087ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state = 42), param_grid=params).fit(X_train, y_train)\n",
    "grid_train_acc = grid.score(X_train, y_train)\n",
    "grid_test_acc = grid.score(X_test, y_test)\n",
    "best_params = grid.best_params_\n",
    "print(f'Training Accuracy: {grid_train_acc: .3f}')\n",
    "print(f'Test Accuracy: {grid_test_acc: .3f}')\n",
    "print(f'Best parameters of tree: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomizedSearchCV\n",
    "random = RandomizedSearchCV(DecisionTreeClassifier(random_state = 42), params).fit(X_train, y_train)\n",
    "random_train_acc = random.score(X_train, y_train)\n",
    "random_test_acc = random.score(X_test, y_test)\n",
    "best_params = random.best_params_\n",
    "print(f'Training Accuracy: {random_train_acc: .3f}')\n",
    "print(f'Test Accuracy: {random_test_acc: .3f}')\n",
    "print(f'Best parameters of tree: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HalvingGridSearchCV\n",
    "halving = HalvingGridSearchCV(DecisionTreeClassifier(random_state = 42), param_grid=params).fit(X_train, y_train)\n",
    "halving_train_acc = halving.score(X_train, y_train)\n",
    "halving_test_acc = halving.score(X_test, y_test)\n",
    "best_params = halving.best_params_\n",
    "print(f'Training Accuracy: {halving_train_acc: .3f}')\n",
    "print(f'Test Accuracy: {halving_test_acc: .3f}')\n",
    "print(f'Best parameters of tree: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af98ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HalvingRandomSearchCV\n",
    "halvingrand = HalvingRandomSearchCV(DecisionTreeClassifier(random_state = 42), params).fit(X_train, y_train)\n",
    "halvingrand_train_acc = halvingrand.score(X_train, y_train)\n",
    "halvingrand_test_acc = halvingrand.score(X_test, y_test)\n",
    "best_params = halvingrand.best_params_\n",
    "print(f'Training Accuracy: {halvingrand_train_acc: .3f}')\n",
    "print(f'Test Accuracy: {halvingrand_test_acc: .3f}')\n",
    "print(f'Best parameters of tree: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=zip(SearchCVModel,Training_Accuracy,Test_Accuracy, Max_Depth, Min_Samples_Leaf, Min_Samples_Split),columns=['CVModel','Training_Accuracy','Test_Accuracy', 'Depth(Max)', 'Leaf(Min)', 'Split(Min)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad25d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchCVModel = ['Grid', 'Randomized', 'HalvingGrid', 'HalvingRandom']\n",
    "Training_Accuracy = [0.705, 0.705, 0.705, 0.705]\n",
    "Test_Accuracy = [0.704, 0.704, 0.704, 0.704]\n",
    "Max_Depth = [2, 2, 2, 2]\n",
    "Min_Samples_Leaf = [1, 10, 1, 1]\n",
    "Min_Samples_Split = [0.05, 0.05, 0.05, 0.05]\n",
    "Criterion = [\"Gini\", \"Gini\", \"Gini\", \"Gini\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Visualization of Decision Tree Results\n",
    "kwargs= dict (linestyle='dashed', color=['red', 'green'], linewidth=1.2)\n",
    "line_plot = df.plot(y = ['Training_Accuracy','Test_Accuracy'], figsize= (10,6),**kwargs ) \n",
    "line_plot.set_title('Accuracy Line Plot (Test & Train)')\n",
    "line_plot.grid()\n",
    "plt.xlim([0,3])\n",
    "line_plot.set_xlabel('0.0: GridSearchCV, 1.0: RandomizedSearchCV, 2.0: HalvingGridSearchCV, 3.0: HalvingRandomSearchCV'),\n",
    "line_plot.set_ylabel('Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ac7e2",
   "metadata": {},
   "source": [
    "# All Decision Tree Searches performed similarly, with a test accuracy of 70.4%. Training accuracy was slightly higher than test accuracy (70.5%), but still extremely similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28daa1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "plt.subplots(figsize=(18,19))\n",
    "clf = DecisionTreeClassifier(max_depth = 2, min_samples_leaf=1, min_samples_split = 0.05,\n",
    "                             random_state = 42)\n",
    "clf.fit(X_train, y_train)\n",
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4075e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
